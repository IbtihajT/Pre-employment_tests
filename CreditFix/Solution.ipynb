{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "persistent-depth",
   "metadata": {},
   "source": [
    "## Include required libararies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "turkish-bargain",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from mpl_toolkits import mplot3d\n",
    "from datetime import datetime, date\n",
    "from xgboost import XGBClassifier\n",
    "from xgboost import plot_importance\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charming-error",
   "metadata": {},
   "source": [
    "## Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "greater-cologne",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UNIQUEID</th>\n",
       "      <th>DISBURSED_AMOUNT</th>\n",
       "      <th>ASSET_COST</th>\n",
       "      <th>LTV</th>\n",
       "      <th>BRANCH_ID</th>\n",
       "      <th>SUPPLIER_ID</th>\n",
       "      <th>MANUFACTURER_ID</th>\n",
       "      <th>CURRENT_PINCODE_ID</th>\n",
       "      <th>DATE_OF_BIRTH</th>\n",
       "      <th>EMPLOYMENT_TYPE</th>\n",
       "      <th>...</th>\n",
       "      <th>SEC_SANCTIONED_AMOUNT</th>\n",
       "      <th>SEC_DISBURSED_AMOUNT</th>\n",
       "      <th>PRIMARY_INSTAL_AMT</th>\n",
       "      <th>SEC_INSTAL_AMT</th>\n",
       "      <th>NEW_ACCTS_IN_LAST_SIX_MONTHS</th>\n",
       "      <th>DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS</th>\n",
       "      <th>AVERAGE_ACCT_AGE</th>\n",
       "      <th>CREDIT_HISTORY_LENGTH</th>\n",
       "      <th>NO_OF_INQUIRIES</th>\n",
       "      <th>LOAN_DEFAULT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>420825</td>\n",
       "      <td>50578</td>\n",
       "      <td>58400</td>\n",
       "      <td>89.55</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1441</td>\n",
       "      <td>01-01-1984</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>537409</td>\n",
       "      <td>47145</td>\n",
       "      <td>65550</td>\n",
       "      <td>73.23</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1502</td>\n",
       "      <td>31-07-1985</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>1yrs 11mon</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>417566</td>\n",
       "      <td>53278</td>\n",
       "      <td>61360</td>\n",
       "      <td>89.63</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1497</td>\n",
       "      <td>24-08-1985</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>624493</td>\n",
       "      <td>57513</td>\n",
       "      <td>66113</td>\n",
       "      <td>88.48</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1501</td>\n",
       "      <td>30-12-1993</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 8mon</td>\n",
       "      <td>1yrs 3mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>539055</td>\n",
       "      <td>52378</td>\n",
       "      <td>60300</td>\n",
       "      <td>88.39</td>\n",
       "      <td>67</td>\n",
       "      <td>22807</td>\n",
       "      <td>45</td>\n",
       "      <td>1495</td>\n",
       "      <td>09-12-1977</td>\n",
       "      <td>Self employed</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>0yrs 0mon</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   UNIQUEID  DISBURSED_AMOUNT  ASSET_COST    LTV  BRANCH_ID  SUPPLIER_ID  \\\n",
       "0    420825             50578       58400  89.55         67        22807   \n",
       "1    537409             47145       65550  73.23         67        22807   \n",
       "2    417566             53278       61360  89.63         67        22807   \n",
       "3    624493             57513       66113  88.48         67        22807   \n",
       "4    539055             52378       60300  88.39         67        22807   \n",
       "\n",
       "   MANUFACTURER_ID  CURRENT_PINCODE_ID DATE_OF_BIRTH EMPLOYMENT_TYPE  ...  \\\n",
       "0               45                1441    01-01-1984        Salaried  ...   \n",
       "1               45                1502    31-07-1985   Self employed  ...   \n",
       "2               45                1497    24-08-1985   Self employed  ...   \n",
       "3               45                1501    30-12-1993   Self employed  ...   \n",
       "4               45                1495    09-12-1977   Self employed  ...   \n",
       "\n",
       "  SEC_SANCTIONED_AMOUNT  SEC_DISBURSED_AMOUNT  PRIMARY_INSTAL_AMT  \\\n",
       "0                     0                     0                   0   \n",
       "1                     0                     0                1991   \n",
       "2                     0                     0                   0   \n",
       "3                     0                     0                  31   \n",
       "4                     0                     0                   0   \n",
       "\n",
       "   SEC_INSTAL_AMT  NEW_ACCTS_IN_LAST_SIX_MONTHS  \\\n",
       "0               0                             0   \n",
       "1               0                             0   \n",
       "2               0                             0   \n",
       "3               0                             0   \n",
       "4               0                             0   \n",
       "\n",
       "   DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS  AVERAGE_ACCT_AGE  \\\n",
       "0                                    0         0yrs 0mon   \n",
       "1                                    1        1yrs 11mon   \n",
       "2                                    0         0yrs 0mon   \n",
       "3                                    0         0yrs 8mon   \n",
       "4                                    0         0yrs 0mon   \n",
       "\n",
       "   CREDIT_HISTORY_LENGTH  NO_OF_INQUIRIES  LOAN_DEFAULT  \n",
       "0              0yrs 0mon                0             0  \n",
       "1             1yrs 11mon                0             1  \n",
       "2              0yrs 0mon                0             0  \n",
       "3              1yrs 3mon                1             1  \n",
       "4              0yrs 0mon                1             1  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Path to the csv file\n",
    "dataPath = \"./data/data.csv\"\n",
    "\n",
    "# Load the data\n",
    "rawDataFrame = pd.read_csv(dataPath)\n",
    "\n",
    "# Print some data\n",
    "rawDataFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cardiac-importance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['UNIQUEID', 'DISBURSED_AMOUNT', 'ASSET_COST', 'LTV', 'BRANCH_ID',\n",
       "       'SUPPLIER_ID', 'MANUFACTURER_ID', 'CURRENT_PINCODE_ID', 'DATE_OF_BIRTH',\n",
       "       'EMPLOYMENT_TYPE', 'DISBURSAL_DATE', 'STATE_ID', 'EMPLOYEE_CODE_ID',\n",
       "       'MOBILENO_AVL_FLAG', 'AADHAR_FLAG', 'PAN_FLAG', 'VOTERID_FLAG',\n",
       "       'DRIVING_FLAG', 'PASSPORT_FLAG', 'PERFORM_CNS_SCORE',\n",
       "       'PERFORM_CNS_SCORE_DESCRIPTION', 'PRI_NO_OF_ACCTS', 'PRI_ACTIVE_ACCTS',\n",
       "       'PRI_OVERDUE_ACCTS', 'PRI_CURRENT_BALANCE', 'PRI_SANCTIONED_AMOUNT',\n",
       "       'PRI_DISBURSED_AMOUNT', 'SEC_NO_OF_ACCTS', 'SEC_ACTIVE_ACCTS',\n",
       "       'SEC_OVERDUE_ACCTS', 'SEC_CURRENT_BALANCE', 'SEC_SANCTIONED_AMOUNT',\n",
       "       'SEC_DISBURSED_AMOUNT', 'PRIMARY_INSTAL_AMT', 'SEC_INSTAL_AMT',\n",
       "       'NEW_ACCTS_IN_LAST_SIX_MONTHS', 'DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS',\n",
       "       'AVERAGE_ACCT_AGE', 'CREDIT_HISTORY_LENGTH', 'NO_OF_INQUIRIES',\n",
       "       'LOAN_DEFAULT'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawDataFrame.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-convertible",
   "metadata": {},
   "source": [
    "We can see that there are 233,154 datapoints in the total dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divine-above",
   "metadata": {},
   "source": [
    "## Drop Null Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "painful-explosion",
   "metadata": {},
   "source": [
    "Now we can simply identify the columns that contain NULL values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eligible-tribe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNIQUEID                                  0\n",
       "DISBURSED_AMOUNT                          0\n",
       "ASSET_COST                                0\n",
       "LTV                                       0\n",
       "BRANCH_ID                                 0\n",
       "SUPPLIER_ID                               0\n",
       "MANUFACTURER_ID                           0\n",
       "CURRENT_PINCODE_ID                        0\n",
       "DATE_OF_BIRTH                             0\n",
       "EMPLOYMENT_TYPE                        7661\n",
       "DISBURSAL_DATE                            0\n",
       "STATE_ID                                  0\n",
       "EMPLOYEE_CODE_ID                          0\n",
       "MOBILENO_AVL_FLAG                         0\n",
       "AADHAR_FLAG                               0\n",
       "PAN_FLAG                                  0\n",
       "VOTERID_FLAG                              0\n",
       "DRIVING_FLAG                              0\n",
       "PASSPORT_FLAG                             0\n",
       "PERFORM_CNS_SCORE                         0\n",
       "PERFORM_CNS_SCORE_DESCRIPTION             0\n",
       "PRI_NO_OF_ACCTS                           0\n",
       "PRI_ACTIVE_ACCTS                          0\n",
       "PRI_OVERDUE_ACCTS                         0\n",
       "PRI_CURRENT_BALANCE                       0\n",
       "PRI_SANCTIONED_AMOUNT                     0\n",
       "PRI_DISBURSED_AMOUNT                      0\n",
       "SEC_NO_OF_ACCTS                           0\n",
       "SEC_ACTIVE_ACCTS                          0\n",
       "SEC_OVERDUE_ACCTS                         0\n",
       "SEC_CURRENT_BALANCE                       0\n",
       "SEC_SANCTIONED_AMOUNT                     0\n",
       "SEC_DISBURSED_AMOUNT                      0\n",
       "PRIMARY_INSTAL_AMT                        0\n",
       "SEC_INSTAL_AMT                            0\n",
       "NEW_ACCTS_IN_LAST_SIX_MONTHS              0\n",
       "DELINQUENT_ACCTS_IN_LAST_SIX_MONTHS       0\n",
       "AVERAGE_ACCT_AGE                          0\n",
       "CREDIT_HISTORY_LENGTH                     0\n",
       "NO_OF_INQUIRIES                           0\n",
       "LOAN_DEFAULT                              0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Identify the features with more than 50% NULL Data\n",
    "rawDataFrame.isna().sum(axis=0) # We use axis = 0 so the null values are counted column-wise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "relative-sleeve",
   "metadata": {},
   "source": [
    "We see that the feature `EMPLOYMENT_TYPE` is the only column containing NULL Values. Now there can be 2 options that can be either to drop the entire `EMPLOYMENT_TYPE` feature or just drop the rows that contain the NULL values for this feature. Now due to the large number of total datapoints in the entire dataset (233,154), the amount of NULL values (7,661) is considerable low which is only `3.29%` so it is better to drop the rows instead of droping the whole column as it may contain information that can effect the target variable and losing 3% of the data is not that harmful because we have enough datapoints to generalize on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "every-penalty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows with null values\n",
    "print(f\"Total Number of Datapoints before droping: {len(rawDataFrame)}\")\n",
    "nullDroppedDataframe = rawDataFrame.dropna()\n",
    "print(f\"Total Number of Datapoints after droping: {len(nullDroppedDataframe)}\")\n",
    "print(f\"Total Number of Datapoints dropped: {len(rawDataFrame) - len(nullDroppedDataframe)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loved-publisher",
   "metadata": {},
   "source": [
    "We see that those 7,661 rows are dropped. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-letter",
   "metadata": {},
   "source": [
    "## Add a new Feature of Age"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considered-while",
   "metadata": {},
   "source": [
    "Now let's add a new `Age` feature and compute it using the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple function to get age based on the Date of Birth\n",
    "def getAge(dateOfBirth):\n",
    "    \n",
    "    # Convert string to datetime object and get the date only as `strptime` returns the time as well \n",
    "    dateOfBirth = datetime.strptime(dateOfBirth, \"%d-%m-%Y\").date() # Format Code List can be found at: https://www.programiz.com/python-programming/datetime/strptime\n",
    "    \n",
    "    # Get the current date\n",
    "    today = date.today()\n",
    "    \n",
    "    # Return the age by subtracting date of birth from current date\n",
    "    # We will also consider the dob month and day\n",
    "    # If the current date's month and day is less than the dob's month and day, we subtract an additional year.\n",
    "    return today.year - dateOfBirth.year - ((today.month, today.day) < (dateOfBirth.month, dateOfBirth.day))\n",
    "\n",
    "# Apply the `getAge` method on the entire `DATE_OF_BIRTH` column and create a new feature age    \n",
    "ageDataframe = nullDroppedDataframe['DATE_OF_BIRTH'].apply(getAge)\n",
    "\n",
    "# Add the new `AGE` feature in our dataframe next to `DATE_OF_BIRTH`\n",
    "# Get the Index of `DATE_OF_BIRTH` column in data frame\n",
    "dateOfBirthColumnIndex = nullDroppedDataframe.columns.get_loc('DATE_OF_BIRTH')\n",
    "\n",
    "# Add `AGE` column next to `DATE_OF_BIRTH` column\n",
    "nullDroppedDataframe.insert(dateOfBirthColumnIndex + 1, \"AGE\", ageDataframe)\n",
    "\n",
    "# Print the head of Dataframe to see the new feature\n",
    "nullDroppedDataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "executed-branch",
   "metadata": {},
   "source": [
    "We see that the `Age` Feature has been added next to `DATE_OF_BIRTH` successfuly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-screening",
   "metadata": {},
   "source": [
    "## 1: Feature Correlation with Target Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-scenario",
   "metadata": {},
   "source": [
    "First step is to see how many features are `categorical` in nature. The features that are `categorical` should be converted to numerical features first before measuring the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "committed-basic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's find out the names of the columns that are Categorical in nature\n",
    "\n",
    "# All column names\n",
    "allColumns = nullDroppedDataframe.columns\n",
    "\n",
    "# Column names that only contain numeric data\n",
    "numericColumns = nullDroppedDataframe._get_numeric_data().columns\n",
    "\n",
    "# Columns that contain categorical data\n",
    "nonNumericFeatures = list(set(allColumns) - set(numericColumns))\n",
    "\n",
    "# Let's see the non Numeric Features\n",
    "nullDroppedDataframe[nonNumericFeatures].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "positive-signature",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's also find the Unique category values for categorical Variables\n",
    "uniqueDf = nullDroppedDataframe[nonNumericFeatures].nunique().to_frame().reset_index()\n",
    "uniqueDf.columns = ['Variable', 'Distinct Count']\n",
    "uniqueDf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dutch-saver",
   "metadata": {},
   "source": [
    "We can observe the from all 6 of these `categorical variables` it only makes sence to use `EMPLOYMENT_TYPE` for our analysis purposes as all other features are simply dates or having too many categories. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-daily",
   "metadata": {},
   "source": [
    "So let's just drop the irrelevant columns and convert Categorical Columns to Numeric columns. For this purpose we can go with Pandas `.astype('category').cat.codes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cooperative-banks",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the non required features\n",
    "processedDataFrame = nullDroppedDataframe.drop(['AVERAGE_ACCT_AGE', 'CREDIT_HISTORY_LENGTH', 'DATE_OF_BIRTH', 'DISBURSAL_DATE', 'PERFORM_CNS_SCORE_DESCRIPTION'], axis=1)\n",
    "\n",
    "# Convert Categorical Features to Numerical Feature\n",
    "processedDataFrame['EMPLOYMENT_TYPE'] = processedDataFrame['EMPLOYMENT_TYPE'].astype('category').cat.codes\n",
    "processedDataFrame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fallen-finder",
   "metadata": {},
   "source": [
    "So we have got ridden on `Non-Numeric` data from our dataset and we now only have `Numeric` data. Great!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worthy-maria",
   "metadata": {},
   "source": [
    "Now let's start the analysis by calculating feature correlations. For this purpose we can use a heatmap to get an idea of the features with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Feature Correlation Matrix\n",
    "featureCorrelationMatrix = processedDataFrame.corr()\n",
    "\n",
    "# Plot the `featureCorrelationMatrix` using `seaborn` heatmap\n",
    "plt.figure(figsize=(22, 10))\n",
    "heatmap = sns.heatmap(featureCorrelationMatrix, vmin=-1, vmax=1)\n",
    "heatmap.set_title('Correlation Heatmap', fontdict={'fontsize':18}, pad=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wrapped-green",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the correlation against the target Variable\n",
    "correlationTarget = featureCorrelationMatrix['LOAN_DEFAULT']\n",
    "\n",
    "# Selecting Features with positive correltaion\n",
    "featuresOfInterest = correlationTarget[correlationTarget > 0].sort_values()\n",
    "featuresOfInterest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "steady-prior",
   "metadata": {},
   "source": [
    "These are the features that are positively correlated with the target variable, so we will continue with these features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mathematical-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Positively Correlated Dataframe\n",
    "positivlyCorrelatedDataframe = processedDataFrame[featuresOfInterest.index]\n",
    "positivlyCorrelatedDataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "innovative-accounting",
   "metadata": {},
   "source": [
    "## 2: Demographic Data Impact"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "integral-cartridge",
   "metadata": {},
   "source": [
    "For the feature of age we can see that there is a negative correlation. So this feature doesn't have an impact on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-point",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDataFrame[['AGE', 'LOAN_DEFAULT']].corrwith(processedDataFrame['LOAN_DEFAULT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "critical-record",
   "metadata": {},
   "source": [
    "Where as the feature of `BRANCH_ID` has a correlation above the threshold of `0.02`. But we can see below in the `XGBoost Section` that the feature of `BRANCH_ID` has an `F-Score` of only 223 which is below the threshold of 400 that we will chose to proceed with. So my conclusion will be that both of these features don't play a major role in the decision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pharmaceutical-submission",
   "metadata": {},
   "outputs": [],
   "source": [
    "processedDataFrame[['BRANCH_ID', 'LOAN_DEFAULT']].corrwith(processedDataFrame['LOAN_DEFAULT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "judicial-howard",
   "metadata": {},
   "source": [
    "## 3: Features for feature analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unsigned-banana",
   "metadata": {},
   "source": [
    "Feature that are more than 0.02 correlation can be used for feature analysis as they have a higher imapct on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alpha-northwest",
   "metadata": {},
   "outputs": [],
   "source": [
    "featAnalysisFeatures = correlationTarget[correlationTarget > 0.02].sort_values()\n",
    "featAnalysisFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electric-prompt",
   "metadata": {},
   "source": [
    "We can also use XGBoostClassifier to know the feature importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "corporate-brave",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Dependent and Independent Varibale\n",
    "X = positivlyCorrelatedDataframe[featAnalysisFeatures.index].iloc[:, :-1]\n",
    "y = positivlyCorrelatedDataframe[featAnalysisFeatures.index].iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elementary-minimum",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use `XGBoostClassifier` to check feature importance\n",
    "\n",
    "# Train XGBClassifier with our X, y\n",
    "model = XGBClassifier(use_label_encoder=False)\n",
    "model.fit(X, y)\n",
    "\n",
    "# plot feature importance\n",
    "plot_importance(model)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rocky-analyst",
   "metadata": {},
   "source": [
    "Let's rely on the feature importance showed to us by `XGBClassifier` and get the features that have f-score more than 400"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-scholar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get features that have `F-Score` more than 400\n",
    "X = positivlyCorrelatedDataframe[['UNIQUEID', 'CURRENT_PINCODE_ID', 'LTV', 'EMPLOYEE_CODE_ID', 'DISBURSED_AMOUNT', 'SUPPLIER_ID']].iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-routine",
   "metadata": {},
   "source": [
    "## 4: Estimator Recommendation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clinical-kruger",
   "metadata": {},
   "source": [
    "As we have too many features and it is not able to visualize them in 22 dimensions, we can use `PCA(Principle Component Analysis)` for dimentionality reduction. We use PCA with 2 components so we get two features in return. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "worst-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaning-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ready the PCA\n",
    "pca = PCA(n_components=2).fit_transform(X, y)\n",
    "\n",
    "# Get feat1 and feat2\n",
    "feat1, feat2 = pca[:, 0], pca[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "attended-spice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot in 3 Dimensions. 2 Dimensions will be the features and the 3rd dimension will be the target\n",
    "ax = plt.axes(projection='3d')\n",
    "ax.figure.set_size_inches(15, 15)\n",
    "zline = y\n",
    "xline = feat1\n",
    "yline = feat2\n",
    "ax.scatter3D(zline, xline, yline, c=y.values, cmap=matplotlib.colors.ListedColormap(['blue', 'red']), label=['Bla', 'another']);\n",
    "ax.set_title(\"3D Plot for 2 PCA Components against the Target Variable\", fontsize=18)\n",
    "ax.set_xlabel(\"Target\", fontsize=12)\n",
    "ax.set_ylabel(\"PCA1\", fontsize=12)\n",
    "ax.set_zlabel(\"PCA2\", fontsize=12)\n",
    "loc = np.arange(0,max(y.values),max(y.values)/float(2))\n",
    "# ax.set_ticks(loc)\n",
    "# ax.set_ticklabels(['blue', 'red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-connection",
   "metadata": {},
   "source": [
    "We can see that there is a perfect gap between the 2 classes. So we can use \n",
    "\n",
    "## Supervised Learning\n",
    "##### 1) Deep Neural Network with a Single output Neuron with Softmax or Sigmoid activation\n",
    "##### 2) Logistic Regression\n",
    "##### 3) Naive Bays\n",
    "##### 4) SVM (Support Vector Machine)\n",
    "##### 5) Decision Trees \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
